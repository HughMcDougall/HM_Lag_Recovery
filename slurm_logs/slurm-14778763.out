INFO[2023-04-23 20:08:27,822]: Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
INFO[2023-04-23 20:08:27,822]: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
INFO[2023-04-23 20:08:27,824]: Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
INFO[2023-04-23 20:08:27,824]: Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
WARNING[2023-04-23 20:08:27,824]: No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
SIMBA SAFETY LOAD DEBUG:	 get_args
136 i
bad login of ./SIMBA_jobstatus.dat attempt 1 in get_args
bad login of ./SIMBA_jobstatus.dat attempt 2 in get_args
good login of ./SIMBA_jobstatus.dat in get_args
Beginning job 136 on job list ./SIMBA_jobstatus_oneline.dat with mode line1
SIMBA SAFETY LOAD DEBUG:	 start
136 i
Traceback (most recent call last):
  File "/data/uqhmcdou/HM_Lag_Recovery/LineFit02.py", line 120, in <module>
    main()
  File "/data/uqhmcdou/HM_Lag_Recovery/LineFit02.py", line 97, in main
    SIMBA.start(args.i, table_url = args.table, comment = "%s Job started /w %i chains, %i samples, %i burn in and %i cores. NS-live = %i, NS-samp = %i" %(mode, args.Nchains, args.Nsamples, args.Nburn, args.Ncores, args.NS_numlive, args.NS_maxevals))
  File "/data/uqhmcdou/HM_Lag_Recovery/SIMBA.py", line 75, in wrapped_func
    raise Exception("Attempted to edit non-existant file %s in %s" %(table_url, fname))
Exception: Attempted to edit non-existant file ./SIMBA_jobstatus.dat in start
