INFO[2023-04-21 13:59:22,386]: Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
INFO[2023-04-21 13:59:22,387]: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
INFO[2023-04-21 13:59:22,387]: Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.
INFO[2023-04-21 13:59:22,387]: Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
WARNING[2023-04-21 13:59:22,387]: No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
SIMBA SAFETY LOAD DEBUG:	 get_args
10 i
good login of ./SIMBA_jobstatus.dat in get_args
Beginning job 10 on job list ./SIMBA_jobstatus.dat with mode twoline
Data loaded. Saving normalized lightcurve to ./Data/real_data/10-B-2925637387/banded_data.dat
SIMBA SAFETY LOAD DEBUG:	 start
10 i
Traceback (most recent call last):
  File "/data/uqhmcdou/HM_Lag_Recovery/LineFit01.py", line 126, in <module>
    main()
  File "/data/uqhmcdou/HM_Lag_Recovery/LineFit01.py", line 104, in main
    SIMBA.start(args.i, table_url = args.table, comment = "Job started /w %i chains, %i samples, %i burn in and %i cores" %(args.Nchains, args.Nsamples, args.Nburn, args.Ncores))
  File "/data/uqhmcdou/HM_Lag_Recovery/SIMBA.py", line 75, in wrapped_func
    raise Exception("Attempted to edit non-existant file %s in %s" %(table_url, fname))
Exception: Attempted to edit non-existant file ./SIMBA_jobstatus.dat in start
